{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete sampling\n",
    "In the last problem of the first session we sampled with given probabilities using prefix sums and binary search. The sampling code is the bottleneck of the whole process, its running times is 3 times higher than the code for uniform probabilities, and the difference would only increase for larger number of outcomes. In the next two problems we discuss two simple, but powerful techniques one can use to sample in time $O(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2a.** Consider the problem of sampling with known probabilities $p_1,\\ldots,p_d$. Suppose that you have a black-box that samples with probabilities $q_1,\\ldots,q_d$ that are close to $p_1,\\ldots,p_d$, say\n",
    "$$ \\forall_{i=1,\\ldots,n} p_i \\le (1+\\varepsilon)q_i.$$\n",
    "\n",
    "* How can you use this black-box to sample with probabilities $p_1,\\ldots,p_d$? It is expected, that the running time of the algorithm would be non-deterministic.\n",
    "* Prove that your algorithm is correct.\n",
    "* Implement the algorithm and use it to give a faster implementation for **Problem 1c**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2b.** One of the reasons this implementation is not significantly faster than the one in **Problem 1c** , apart from $d$ being rather small, is that we are using Python's interpreter a bit too much, and Python is slow. One way around this is usually to use a library function - **searchsorted** is much faster than an equivalent code implemented in pure Python. But even if the functionality you need is not implemented in a lower level language as\n",
    "a library function, there is still hope. You can try to implement it using optimized array algebra, for example using **numpy**. In this problem, your task is to rewrite the previous algorithm, so that the amount of *looping* is reduced to a minimum necessary. In particular, you should create a *vectorized* version of random dates generation (in bulk), while the actual search for duplicates remains a loop with a **set**. Here are some useful tips:\n",
    "   * You can perform arithmetic, comparisons, etc. on **numpy** arrays.\n",
    "   * You can generate whole **numpy** arrays of random numbers at once.\n",
    "   * You can even perform parallel look-up like in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-542ca56e10d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.array([10,3,7])\n",
    "I = np.array([1,1,2,2])\n",
    "print(X[I])\n",
    "X = np.array([[1,2],[3,4]])\n",
    "I = np.array([0,0,1])\n",
    "J = np.array([1,0,1])\n",
    "print(X[I,J])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2c (Squaring the histogram).** In this problem, we again want to sample with known probabilities $p_1,\\ldots,p_n$, but this time we make no assumptions on $p_i$. Consider the following algorithm:\n",
    "   * Let $V$ be the mean of $p_i$, i.e. $V=\\frac{1}{n}$.\n",
    "   * Create $n$ buckets, each with volume $V$, put each $p_i$ into a separate bucket.\n",
    "   * Until there exists a bucket $A$ that is not full, find a bucket $B$ that overflows, and trasfer probability from $B$ to $A$ until $A$ is exactly full\n",
    "\n",
    "Show that:\n",
    "   * This algorithm always ends.\n",
    "   * When it ends, each bucket contains pieces of exactly two $p_i$'s.\n",
    "\n",
    "How to use the result of this algorithm to sample with probabilities $p_i$. Argue that your algorithm is correct and implement it. The sampling part should be *vectorized*. Use this algorithm to sample birthdates again, and test its efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operation of transferring probability from one bucket to another doesn't change mean ($V = 1/n$).\n",
    "\n",
    "In each step we have two options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([3, 4, 2, 4, 4]), array([ 0.  ,  0.25,  0.5 ,  0.25,  0.5 ]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "p = np.linspace(0, 1, num=5)\n",
    "\n",
    "def squaring_histogram(p):\n",
    "    B = np.array(p, dtype='f') # Bucket\n",
    "    N = B.size\n",
    "\n",
    "    mean = np.mean(B)\n",
    "    \n",
    "    Donor = np.arange(N)\n",
    "    Probs = np.empty(N)\n",
    "    Probs.fill(mean)\n",
    "    \n",
    "    # original  p_i < Probs[i] | donor|Mean \n",
    "    # *************************|******|Mean\n",
    "\n",
    "    while np.count_nonzero(B < mean):\n",
    "\n",
    "        i = np.where(B < mean)[0][0]\n",
    "        j = np.where(B > mean)[0][0]\n",
    "\n",
    "        Donor[i] = j\n",
    "        Probs[i] = B[i]\n",
    "        \n",
    "        B[j] = B[j] - (mean - B[i])\n",
    "        B[i] = mean\n",
    "        \n",
    "    return Donor, Probs\n",
    "\n",
    "print squaring_histogram(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  41,  42,  43,  44,  45,  46,  47,  48,  50,  52,  53,  54,\n",
       "        56,  57,  58,  59,  60,  61,  62,  64,  66,  69,  70,  71,  72,\n",
       "        73,  74,  75,  77,  78,  80,  81,  82,  83,  85,  87,  89,  90,\n",
       "        91,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
       "       122, 123, 126, 127, 128, 129, 130, 132, 133, 135, 138, 139, 140,\n",
       "       142, 145, 146, 148, 150, 151, 152, 155, 156, 158, 160, 161, 167,\n",
       "       168, 169, 170, 171, 172, 174, 177, 178, 179, 180, 181, 185, 186,\n",
       "       187, 190, 191, 192, 193, 195, 197, 198, 200, 201, 202, 203, 204,\n",
       "       211, 212, 213, 215, 216, 217, 219, 221, 222, 223, 224, 225, 226,\n",
       "       227, 230, 234, 236, 242, 243, 245, 249, 250, 252, 253, 254, 255,\n",
       "       256, 257, 258, 259, 262, 264, 266, 268, 270, 272, 277, 279, 280,\n",
       "       282, 284, 285, 286, 292, 293, 295, 296, 299, 302, 304, 307, 309,\n",
       "       310, 314, 315, 316, 320, 321, 322, 323, 325, 326, 331, 333, 336,\n",
       "       338, 349, 351, 352, 354, 358, 362, 364, 365, 366, 367, 369, 371,\n",
       "       375, 376, 378, 379, 382, 383, 386, 387, 398, 399])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('us_births_69_88.csv')\n",
    "births = np.array(data['births'])\n",
    "\n",
    "n = births.size\n",
    "mean = np.mean(births)\n",
    "K = 400\n",
    "\n",
    "sample_days = np.random.randint(0, n-1, K)\n",
    "sample_births = np.random.random_sample(K) * mean\n",
    "\n",
    "Donor, Probs = squaring_histogram(births)\n",
    "\n",
    "# Brutal for\n",
    "days = []\n",
    "for i in range(K):\n",
    "    day = sample_days[i]\n",
    "    day_prob = sample_births[i]\n",
    "    \n",
    "    if day_prob < Probs[day]:\n",
    "        days.append(day)\n",
    "    else:\n",
    "        days.append(Donor[day])\n",
    "\n",
    "# Vectorizing to get the same result as in for above\n",
    "use_original_value = sample_births < Probs[sample_days]\n",
    "use_donor_value = ~use_original_value\n",
    "sample_days[use_donor_value] = Donor[sample_days[use_donor_value]]\n",
    "\n",
    "# Trying to figure out where repetition took place\n",
    "_, indx = np.unique(sample_days, return_index=True)\n",
    "# print(_, indx)\n",
    "indx.sort()\n",
    "indx\n",
    "# indxs = np.arange(K)\n",
    "# indxs[indx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2d.** Show that the frequency histogram for empirical birthday frequencies can actually be computed exactly, and implement your idea. To this end, design a recurence relation using conditional probabilities and use dynamic programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
